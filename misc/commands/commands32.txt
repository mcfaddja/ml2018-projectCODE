import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn import metrics
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn import svm
from sklearn.svm import SVC, LinearSVC
from sklearn.svm import SVR, LinearSVR
from sklearn import linear_model
from sklearn.externals import joblib
import timeit
import time
likes = pd.read_csv("/home/jamster/data/training/relation/relation.csv")
likesUIDs = likes.ix[:,1].values
likesLIDs = likes.ix[:,2].values
lsLikesUIDs = likesUIDs.tolist()
lsLikesLIDs = likesLIDs.tolist()
setLikesUIDs = set(lsLikesUIDs)
setLikesLIDs = set(lsLikesLIDs)
unqLikesUIDs = (list(setLikesUIDs))
unqLikesLIDs = (list(setLikesLIDs))
allLikesLS = [lsLikesUIDs, [str(x) for x in lsLikesLIDs]]
allLikesLS = list(map(list, zip(*allLikesLS)))
likes = None
aDictLikes2 = {}
for aUID in unqLikesUIDs:
	aDictLikes2[aUID]=[]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
combDICT = {}
for uid in unqLikesUIDs:
	tmpDICT={}
	tmpLS = aDictLikes2[uid]
	for row in tmpLS:
		tmpDICT[str(row)]=1
	combDICT[uid]=tmpDICT
tryTHIS=[]
for uid in unqLikesUIDs:
	tryTHIS.append(combDICT[uid])
v = DictVectorizer()
likesMAT=v.fit_transform(tryTHIS)
likesUIDs=None
likesLIDs=None
lsLikesUIDs=None
lsLikesLIDs=None
setLikesUIDs=None
setLikesLIDs=None
unqLikesUIDs=None
unqLikesLIDs=None
allLikesLS=None
aDictLikes2=None
combDICT=None
tryTHIS=None
v=None
profilesDF=pd.read_csv("/home/jamster/data/training/profile/profile.csv")
profilesDF=None
import scipy.sparse
vals, vecs = scipy.sparse.eigs(likesMAT, k=2500)
from scipy.sparse.linalg import svds, eigs
combLIKES=likesMAT.transpose()*likesMAT
import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn import metrics
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn import svm
from sklearn.svm import SVC, LinearSVC
from sklearn.svm import SVR, LinearSVR
from sklearn import linear_model
from sklearn.externals import joblib
import timeit
import time
combLIKESo=combLIKES.copy()
combLIKES=combLIKESo.tocsc()
likesMAT=None
combLIKESo=None
from scipy.sparse.linalg import svds, eigs
vals=None
vecs=None
vals, vecs = eigs(combLIKES, k=2500)
vals, vecs = eigs(combLIKES, k=2000)
print(type(vals))
np.savetxt('/home/jamster/first2000eigenvals.csv', vals, delimiter=",")
np.savetxt('/home/jamster/first2000eigenvals0.csv', vals, delimiter=",")
realVALS=[]
for row in vals:
lsVALS=vals.tolist()
for row in vals.tolist():
	realVALS.append(complex(row).real)
print(realVALS)
import csv
with open('/home/jamster/first2000eigenvals.csv', 'w') as csvfile:
	csvwriter = csv.writer(csvfile)
	for row in realVALS:
		csvwriter.writerow(row)
realVALS=np.array(realVALS)
csvfile.close()
with open('/home/jamster/first2000eigenvals.csv', 'w') as csvfile:
	csvwriter = csv.writer(csvfile)
	for row in realVALS:
		csvwriter.writerow(row)
print(realVALS.shape)
realVALS=realVALS.reshape(2000,1)
csvfile.close()
with open('/home/jamster/first2000eigenvals.csv', 'w') as csvfile:
	csvwriter = csv.writer(csvfile)
	for row in realVALS:
		csvwriter.writerow(row)
csvfile.close()
numCMDs=readline.get_current_history_length()
