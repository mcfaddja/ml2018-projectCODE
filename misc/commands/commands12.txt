range(0, 105, 10)
print(range(0, 105, 10))
tmp = range(0, 105, 10)
print(tmp)
import pandas
range(0, 105, 10)
tmp = range(0, 105, 10)
print(tmp)
for i in range(0, 105, 10):
print(i)
for i in range(0, 105, 10):
	print(i)
import pandas as pd
data = {'uid': [1,1,1,2,2,2,2,3,3,3,3,3,4,4,4,5,5,5,5], 'lid': ['a','c','d','a','b','e','f','b','c','d','e','b','c','e','a','c','e','d']}
df=pd.DataFrame(data)
data = {'uid': [1,1,1,2,2,2,2,3,3,3,3,3,4,4,4,5,5,5,5], 'lid': ['a','c','d','a','b','e','f','b','c','d','e','b','c','e','a','c','e','d','b']}
df=pd.DataFrame(data)
grouped=df.groupby('uid')
print(grouped)
print(grouped.groups)
dums=pd.get_dummies(df)
print(dums)
crs=pd.crosstab(df['uid'],df['lid'])
print(crs)
likes=pd.read_csv("~/data/training/relation/relation.csv")
likesDF = pd.DataFrame(likes)
likes = Non4
likes = None
profiles=pd.read_csv("~/data/training/profile/profile.csv")
profilesDF = pd.DataFrame(profiles)
profiles=None
fullDF = pd.merge(likesDF, profilesDF, on='userid')
print(fullDF.shape)
print(fullDF.columns.tolist())
print(fullDF)
print(likesDF)
print(profilesDF)
likesDF=likesDF['userid','like_id']
likesDF=[likesDF['userid'], likesDF['like_id']]
print(likesDF)
likes={'userid': likesDF['userid'], 'like_id': likesDF['like_id']}
likes={'userid': likesDF[['userid']], 'like_id': likesDF[['like_id']]}
likesDF=likesDF[['userid','like_id']]
likes=pd.read_csv("~/data/training/relation/relation.csv")
likesDF = pd.DataFrame(likes)
likesDF=likesDF[['userid','like_id']]
print(likesDF)
profilesDF=profilesDF[["userid","age","gender","ent","agr","opn","neu","con"]]
profilesDF=profilesDF[["userid","age","gender","ext","agr","ope","neu","con"]]
print(profilesDF)
fullDF = pd.merge(likesDF, profilesDF, on='userid')
print(fullDF)
testME = pd.crosstab(index=fullDF['like_id'],columns=fullDF['age'])
print(testME)
ageDFo = fullDF[['like_id', 'age']]
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=['xx-24','25-34','35-49','50+'])
ageDF = pd.crosstab(ageDFo['age_grp'], ageDFo['like_id'])
print(ageDF.columns.tolist())
tmp1=ageDF.columns.tolist()
print(tmp1[0]
)
print(ageDF)
print(ageDF['age_grp'])
print(ageDF[['age_grp']])
ageDF = pd.DataFrame(ageDF)
print(ageDF)
age_grps={}
for i in range(0,len(fullDF['age'])):
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=['xx-24','25-34','35-49','50+'])
age_grps=ageDFo['age_grp
age_grps=ageDFo['age_grp'].unique()
print(age_grps)
likeIDs=ageDFo['like_id'].unique()
print(len(likeIDs))
ageDF=pd.crosstab(index=[1,2,3,4],columns=ageDFo['like_id'],rowNames=age_grps)
ageDF=pd.crosstab(index=[1,2,3,4],columns=ageDFo['like_id'],rownames=age_grps)
print(ageDF)
ageDF=pd.crosstab(index=ageDFo['age_grp'],columns=ageDFo['like_id'],rownames=age_grps)
ageDF=pd.crosstab(index=ageDFo['age_grp'],columns=ageDFo['like_id'])
tmp3=ageDF.rows.tolist()
tmp3=ageDF['xx-24']
tmp3=ageDF[['xx-24']]
tmp3=ageDF[['age_grp']]
tmp3=ageDF['age_grp']
tmp3=ageDF['like_id']
tmp3=ageDF(0,:)
tmp3=ageDF[0,:]
tmp3=ageDF.ix[0,:]
print(size(tmp3))
print(len(tmp3))
ageDFoo={}
age_grps
age_grps=ageDFo['age_grp'].unique()
for row in age_grps:
	print(row)
age_grps2=['xx-24','25-34','35-49','50+']
for i in range(0,4):
	name = age_grps2[i]
	aTMP = ageDF.ix[0,:]
	ageDFoo[name]=aTMP
print(ageDFoo)
ageDFoo = pd.DataFrame(ageDFoo)
print(ageDFoo)
history()
	aTMP = ageDF.ix[i,:]
ageDFoo={}
for i in range(0,4):
	name = age_grps2[i]
	aTMP = ageDF.ix[0,:]
	ageDFoo[name]=aTMP
print(ageDFoo)
ageDFoo={}
for i in range(0,4):
	name = age_grps2[i]
	aTMP = ageDF.ix[0,:]
	aTMP.drop(0)
	ageDFoo[name]=aTMP
for i in range(0,4):
...     name = age_grps2[i]
for i in range(0,4):
	name=age_grps2[i]
	aTMP = ageDF.ix[0,:]
	print(aTMP)
	aTMP = ageDF.ix[0,1:]
aTMP = ageDF.ix[0,1:]
for i in range(0,4):
	name = age_grps(i)
	aTMP = ageDF.ix[i,1:]
	ageDFoo[name]=aTMP
for i in range(0,4):
	name = age_grps2(i)
	aTMP = ageDF.ix[i,1:]
	ageDFoo[name]=aTMP
for i in range(0,4):
	name = age_grps2[i]
	aTMP = ageDF.ix[i,1:]
	ageDFoo[name]=aTMP
print(ageDFoo)
	aTMP = ageDF.ix[i,:1]
aTMP = ageDF.ix[i,:1]
print(len(aTMP))
aTMP = ageDF.ix[i,2:]
print(len(aTMP)
)
aTMP = ageDF.ix[i,:]
print(len(aTMP))
aTMP=aTMP[1:]
print(len(aTMP))
print(aTMP)
import readline
f = open('/Users/jamster/Downloads/commands9.txt', 'w')
for i in range(readline.get_current_history_length()):
	f.write(readline.get_history_item(i+1) + '\n')
f.close()
quit()
import pandas as pd
import numby as np
import numy as np
quit()
import numpy as np
import pandas as pd
import scipy
import scipy.sparse
import readline
likes = pd.read_csv("/home/Users/jamster/data/training/relation/relation.csv")
quit()
import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
likes = pd.read_csv("/Users/jamster/data/training/relation/relation.csv")
likesUIDs = likes.ix(:,1).values
likesUIDs = likes.ix[:,1].values
likesUIDs = likes.ix[:,1].values.tolist()
likesLIDs = likes.ix[:,2].values.toList()
print(likes.ix[1,2])
likesLIDs = likes.ix[:,2].values
quit()
import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
likes = pd.read_csv("/Users/jamster/data/training/relation/relation.csv")
likesUIDs = likes.ix[:,1].values
likesLIDs = likes.ix[:,2].values
lsLikesUIDs = likesUIDs.tolist()
lsLikesLIDs = likesLIDs.tolist()
setLikesUIDs = set(lsLikesUIDs)
setLikeeLIDs = set(lsLikesLIDs)
setLikesLIDs = set(lsLikesLIDs)
unqLikesUIDs = (list(setLikesUIDs))
unqLikesLIDs = (list(setLikesLIDs))
print(len(unqLikesUIDs))
print(len(unqLikesLIDs))
print(lsLikesUIDs.index(00))
print(lsLikesUIDs.index('00'))
print(if '00' in lsLikesUIDs)
print(if '00' in lsLikesUIDs: print(test))
if '00' in lsLikesUIDs:
	print(test)
if '00' in lsLikesUIDs:
	print(test)
else:
	print(oops)
if '00' in lsLikesUIDs:
	print('test')
else:
	print('no')
numCMDS = readline.get_current_history_length()
for i in range(numCMDS):
	print(readline.get_history_item(i+1))
f = open("/Users/jamster/Desktop/commands10.txt", "w")
for i in range(numCMDS):
	tmp = readline.get_history_item(i+1)
	f.write(tmp + '\n')
f.close()
for i in range(numCMDS):
	print(readline.get_history_item(i+1))
print(len(likes))
aTest = range(0,9500)
print(aTest)
aTest = list(range(0,9500))
print(aTest)
dicLikes = {'userid': lsLikesUIDs, 'like_id': lsLikesLIDs}
dicLikes['userid'][1]
import sklearn
vecIZERlikes=CountVectorizer(analyzed='word')
vecIZERlikes=sklearn.feature_extraction.text.CountVectorizer(analyzer='word')
import sklearn.feature_extraction
vecIZERlikes=CountVectorizer(analyzer='word')
vecIZERlikes=text.CountVectorizer(analyzer='word')
import sklearn.feature_extraction.text.CountVectorizer()
import sklearn.feature_extraction.text.CountVectorizer
vecIZERlikes = sklearn.feature_extraction.text.CountVectorizer(analyzer='word')
vecIZER = sklearn.feature_extraction.text.CountVectorizer(analyzer='word')
vecLIKES=vecIZER.transform(dicLikes)
vecLIKES=vecIZER.transform(dicLikes['like_id'])
vecIZER.fit(dicLikes['like_id'])
dicLikes = {'userid': lsLikesUIDs, 'like_id': str(lsLikesLIDs)}
print(dicLikes['like_id'][1])
print(dicLikes['like_id'][100])
dicLikes = {'userid': lsLikesUIDs, 'like_id': lsLikesLIDs}
print(dicLikes['like_id'][100])
dicLikes = {'userid': lsLikesUIDs, 'like_id': map(str, lsLikesLIDs)}
print(dicLikes['like_id'][100])
dicLikes = {'userid': lsLikesUIDs, 'like_id': map(str, input(lsLikesLIDs))}
print(dicLikes['like_id'][100])
myTST=map(str, lsLikesLIDs)
print(myTST)
myTST=map(str, input(lsLikesLIDs))
print(myTST)
dicLikes = {'userid': lsLikesUIDs, 'like_id': [str(x) for x in lsLikesLIDs}
dicLikes = {'userid': lsLikesUIDs, 'like_id': [str(x) for x in lsLikesLIDs]}
print(dicLikes['like_id'][100])
print(dicLikes['userid'][100])
vecIZER.fit(dicLikes['like_id'])
someTST = vecIZER.transform(dicLikes)
print(someTST.shape)
vecIZER.fit(dicLikes['userid'])
someTST = vecIZER.transform(dicLikes)
print(someTST.shape)
for aUid in unqLikesUIDs:
aDictLikes2 = {}
for aUid in unqLikesUIDs:
	aDictLikes2[aUid]=[]
xHuh = "?"
for row in likes:
	xHuh = row
print(row)
print(row[0])
print(row[1])
allLikesLS = [lsLikesUIDs, lsLikesLIDs]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
print(row[0])
print(row[2])
print(row[1])
allLikesLS = [lsLikesUIDs; lsLikesLIDs]
for first, second in allLikesLS:
	test = 1
print(allLikesLS[0][1]
)
allLikesLS = [lsLikesUIDs, [str(x) for x in lsLikesLIDs]]
for row in allLikesLS:
	dude = 1
print(row)
allLikesLS = list(map(allLikesLS, zip(*l)))
allLikesLS = list(map(list, zip(*allLikesLS)))
print(allLikesLS[0])
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
print(aDictLikes2['c6a9a43058c8cc8398ca6e97324c0fae'])
row[1]
aDictLikes2 = {}
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
aDictLikes2 = {}
for aUID in unqLikesUIDs:
	aDictLikes2[aUID]=[]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
print(aDictLikes2['c6a9a43058c8cc8398ca6e97324c0fae'])
theMAT = vecIZERlikes(aDictLikes2)
vecIZER.fit(dicLikes['like_id'])
vecIZER.transform(dicLikes)
theMAT=vecIZER.transform(aDictLikes2)
print(theMAT.shape)
vecIZER.fit(dicLikes['userid'])
theMAT2=vecIZER.transform(aDictLikes2)
print(theMAT2.shape)
theMAT2=theMAT.transpose()
print(theMAT2.shape)
print(theMAT.max())
print(theMAT.maximum(())
vecIZER.fit(aDictLikes2)
theMAT3=vecIZER.transform(aDictLikes2)
print(theMAT3.shape)
print(theMAT.nonzero())
vecIZER = sklearn.feature_extraction.text.CountVectorizer(analyze=string)
vecIZER = sklearn.feature_extraction.text.CountVectorizer(analyze='word', vocabulary=unqLikesLIDs)
vecIZER = sklearn.feature_extraction.text.CountVectorizer(analyzer='word', vocabulary=unqLikesLIDs)
nowNOW=vecIZER.fit_transform(aDictLikes2)
print(nowNOW.nonzero())
aDictLikes3 = {}
for uid in unqLikesUIDs:
testDict={'a': ['1','2','3'], 'b':[4,5,6]}
print(testDict['a'])
aDictLikes3 = {'userid': [], 'like_id': []}
for uid in unqLikesUIDs:
	aDictLikes3['userid'].append[uid]
	aDictLikes3['like_id'].append[""]
aDictLikes2
aDictLikes2['091bbf7605fa610961cc16950f12c55d']
print(aDictLikes['091bbf7605fa610961cc16950f12c55d'])
print(aDictLikes2['091bbf7605fa610961cc16950f12c55d'])
cnt=0
for uid in unqLikesUIDs:
	tmp=aDictLikes2[uid]
	temp=len(tmp)
	cnt+=temp
print(cnt)
aDictLikes3 = {}
for uid in unqLikesUIDs:
	aDictLikes3[uid]=''
for uid in unqLikesUIDs:
	tmpLS = aDictLikes2[uid]
	tmpSTR = ""
	for row in tmpLS:
		tmpSTR = tmpSTR + " " + str(row)
for uid in unqLikesUIDs:
	tmpLS = aDictLikes2[uid]
	tmpSTR = ""
	isFirst=True
	for row in tmpLS:
		if isFirst:
			tmpSTR = str(row)
			isFirst=False
		else:
			tmpSTR = tmpSTR + " " + str(row)
	aDictLikes3[uid]=tmpSTR
print(aDictLikes3['091bbf7605fa610961cc16950f12c55d']
)
vecIZER = sklearn.feature_extraction.text.CountVectorizer(analyzer='word', vocabulary=[str(x) for x in unqLikesLIDs])
works2=vecIZER.fit_transform(aDictLikes3)
print(works2.shape)
print(works2.nonzero())
unqLikesLIDs.index(5569318595)
unqLikesLIDs.index(5569318594)
unqLikesLIDs.index(5569318592)
unqLikesLIDs[0]
aDictLikes3['091bbf7605fa610961cc16950f12c55d'].index('120460067995648')
aDictLikes3['091bbf7605fa610961cc16950f12c55d'].count('120460067995648')
aDictLikes3['091bbf7605fa610961cc16950f12c55d'].count('147304721968397')
worksMAT = coo_matrix((len(unqLikesUIDs), len(unqLikesLIDs), dtype=np.int8)
worksMAT = coo_matrix((len(unqLikesUIDs), len(unqLikesLIDs)), dtype=np.int8)
from scipy.sparse import coo_matrix
worksMAT = coo_matrix((len(unqLikesUIDs), len(unqLikesLIDs)), dtype=np.int8)
cntX=0
for uid in unqLikesUIDs:
	cntY=0
	for lid in unqLikesLIDs:
cntROW = 0
for uid in unqLikesUIDs:
	cntCOL = 0
	tmpSTR = aDictLikes3[uid]
	for lid in unqLikesLIDs:
cntROW = 0
for uid in unqLikesUIDs:
	cntCOL = 0
	tmpSTR = aDictLikes3[uid]
	tmpCNT=0
	for lid in unqLikesLIDs:
		tmpCNT=tmpSTR.count(str(lid))
		if tmpCNT != 0
cntROW = 0
for uid in unqLikesUIDs:
	cntCOL = 0
	tmpSTR = aDictLikes3[uid]
	for lid in unqLikesLIDs:
		tmpCNT=tmpSTR.count(str(lid))
		if tmpCNT != 0:
workMAT = scipy.sparse.csr_matrix((len(unqLikesUIDs), len(unqLikesLIDs)), dtype=np.int8)
cntROW = 0
for uid in unqLikesUIDs:
	cntCOL = 0
	tmpSTR = aDictLikes3[uid]
	for lid in unqLikesLIDs:
		tmpCNT=tmpSTR.count(str(lid))
		if tmpCNT != 0:
			workMAT[cntROW,cntCOL]=tmpCNT
		cntCOL+=1
	cntROW+=1
vecIZER = sklearn.feature_extraction.text.CountVectorizer(analyzer='char', vocabulary=[str(x) for x in unqLikesLIDs])
vecIZER.fit(unqLikesLIDs)
vecIZER.fit([str(x) for x in unqLikesLIDs])
maybe=vecIZER.transform(aDictLikes2)
print(maybe.shape)
maybe.nonzero()
from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_selection import SelectKBest, chi2
v = DictVectorizer()
X = v.fit_transform(aDictLikes2)
X = v.fit_transform([likesUIDs, likesLIDs])
likesLIDs.tostring()
likesLIDs2 = [str(x) for x in likesLIDs]
print(likesLIDs2)
X = v.fit_transform([likesUIDs, likesLIDs])
v = DictVectorizer()
print(list(range(5))
)
D = []
lsALLo=[lsLikesUIDs, lsLikesLIDs]
lsALL=list(map(list, zip(*lsALLo)))
D = {}
for row in lsALL:
	D[row[0]]=str(row[1])
X = v.fit_transform(D)
print(X.shape)
D = []
for row in lsALL:
	D.append({row[0]: str(row[1])})
X = v.fit_transform(D)
print(X.shape)
combDICT = {}
for uid in unqLikesUIDs"
for uid in unqLikesUIDs:
	tmpDICT={}
	tmpLS = aDictLikes2[uid]
	for row in tmpLS:
		tmpDICT[str(row)]=1
	combDICT[uid]=tmpDICT
print(unqLikesUIDs[0])
print(combDICT['3b64af66ffdc5566f3971e9fe5597505'])
comeON=v.fit_transform(combDICT)
comeON=v.fit_transform(combDICT['3b64af66ffdc5566f3971e9fe5597505'])
print(comeON.shape)
tryTHIS=[]
for uid in unqLikesUIDs:
	tryTHIS.append(combDICT[uid])
comeON=v.fit_transform(tryTHIS)
print(comeON.shape)
print(comeON.nonzero())
numCMDs
numCMDs = readline.get_current_history_length()
f = open("/Users/jamster/Desktop/commands10a.txt", "w")
for i in range(numCMDs):
	f.write(readline.get_history_item(i+1) + '\n')
f.close()
print(comeON.shape)
quit()
import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
likes = pd.read_csv("/Users/jamster/data/training/relation/relation.csv")
likesUIDs = likes.ix[:,1].values
likesLIDs = likes.ix[:,2].values
lsLikesUIDs = likesUIDs.tolist()
lsLikesLIDs = likesLIDs.tolist()
setLikesUIDs = set(lsLikesUIDs)
setLikesLIDs = set(lsLikesLIDs)
unqLikesUIDs = (list(setLikesUIDs))
unqLikesLIDs = (list(setLikesLIDs))
aDictLikes2 = {}
for aUid in unqLikesUIDs:
	aDictLikes2[aUid]=[]
allLikesLS = [lsLikesUIDs; lsLikesLIDs]
allLikesLS = [lsLikesUIDs, lsLikesLIDs]
allLikesLS = [lsLikesUIDs, [str(x) for x in lsLikesLIDs]]
allLikesLS = list(map(list, zip(*allLikesLS)))
aDictLikes2 = {}
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
for aUID in unqLikesUIDs:
	aDictLikes2[aUID]=[]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
aDictLikes2 = {}
for aUID in unqLikesUIDs:
	aDictLikes2[aUID]=[]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
combDICT = {}
for uid in unqLikesUIDs:
	tmpDICT={}
	tmpLS = aDictLikes2[uid]
	for row in tmpLS:
		tmpDICT[str(row)]=1
	combDICT[uid]=tmpDICT
tryTHIS=[]
for uid in unqLikesUIDs:
	tryTHIS.append(combDICT[uid])
from sklearn.feature_extraction import DictVectorizer
v = DictVectorizer()
comeON=v.fit_transform(tryTHIS)
print(comeON.shape)
print(comeON.nonzero())
print(type(comeON))
spDFlikes=pd.SparseDataFrame(comeON,index=unqLikesUIDs,columns=[str(x) for x in unqLikesLIDs])
spDFlikes=None
numCMDs=readline.get_current_history_length()
f=open("/Users/jamster/Desktop/commands11.txt", "w")
for i in range(numCMDs):
	f.write(readline.get_history_item(i+1) + '\n')
f.close()
quit()
import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
likes = pd.read_csv("/Users/jamster/data/training/relation/relation.csv")
likesUIDs = likes.ix[:,1].values
likesLIDs = likes.ix[:,2].values
lsLikesUIDs = likesUIDs.tolist()
lsLikesLIDs = likesLIDs.tolist()
setLikesUIDs = set(lsLikesUIDs)
setLikesLIDs = set(lsLikesLIDs)
unqLikesUIDs = (list(setLikesUIDs))
unqLikesLIDs = (list(setLikesLIDs))
allLikesLS = [lsLikesUIDs, lsLikesLIDs]
allLikesLS = [lsLikesUIDs, [str(x) for x in lsLikesLIDs]]
allLikesLS = list(map(list, zip(*allLikesLS)))
aDictLikes2 = {}
for aUID in unqLikesUIDs:
	aDictLikes2[aUID]=[]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
combDICT = {}
for uid in unqLikesUIDs:
	tmpDICT={}
	tmpLS = aDictLikes2[uid]
	for row in tmpLS:
		tmpDICT[str(row)]=1
	combDICT[uid]=tmpDICT
tryTHIS=[]
for uid in unqLikesUIDs:
	tryTHIS.append(combDICT[uid])
from sklearn.feature_extraction import DictVectorizer
v = DictVectorizer()
comeON=v.fit_transform(tryTHIS)
profiles=pd.read_csv("/Users/jamster/data/profile/profile.csv")
profiles=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
print(profiles.columns.tolist())
profUIDs=profiles.ix[:,1]
profAGEs=profiles.ix[:,2]
profSEXs=profiles.ix[:,3]
profOPEs=profiles.ix[:,4]
profCONs=profiles.ix[:,5]
profEXTs=profiles.ix[:,6]
profAGRs=profiles.ix[:,7]
profNEUs=profiles.ix[:,8]
profUIDs=profiles.ix[:,1].values
profAGEs=profiles.ix[:,2].values
profSEXs=profiles.ix[:,3].values
profOPEs=profiles.ix[:,4].values
profCONs=profiles.ix[:,5].values
profEXTs=profiles.ix[:,6].values
profAGRs=profiles.ix[:,7].values
profNEUs=profiles.ix[:,8].values
from sklearn import metrics
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.model_selection import KFold
print(type(profUIDs)
)
print(profUIDs.shape)
test = np.array(profUIDs,profAGEs)
test = np.concatenate((profUIDs,profAGEs), axis=1)
test = np.concatenate((profUIDs,profAGEs), axis=0)
print(test.shape)
test0=profUIDs.reshape(9500,1)
print(test0.shape)
test1=profAGEs.reshape(9500,1)
test = np.concatenate((test0, test1), axis=1)
print(test.shape)
profUIDs0 = profUIDs.reshape(9500,1)
profAGEs0 = profAGEs.reshape(9500,1)
profSEXs0 = profSEXs.reshape(9500,1)
profOPEs0 = profOPEs.reshape(9500,1)
profCONs0 = profCONs.reshape(9500,1)
profEXTs0 = profEXTs.reshape(9500,1)
profAGRs0 = profAGRs.reshape(9500,1)
profNEUs0 = profNEUs.reshape(9500,1)
profUIDs0 = profUIDs.reshape(9500,1)
profAGEs0 = profAGEs.reshape(9500,1)
profSEXs0 = profSEXs.reshape(9500,1)
profOPEs0 = profOPEs.reshape(9500,1)
profCONs0 = profCONs.reshape(9500,1)
profEXTs0 = profEXTs.reshape(9500,1)
profAGRs0 = profAGRs.reshape(9500,1)
profNEUs0 = profNEUs.reshape(9500,1)
profAGEs1 = np.concatenate((profUIDs0, profAGEs0), axis=1)
profSEXs1 = np.concatenate((profUIDs0, profSEXs0), axis=1)
profOPEs1 = np.concatenate((profUIDs0, profOPEs0), axis=1)
profCONs1 = np.concatenate((profUIDs0, profCONs0), axis=1)
profEXTs1 = np.concatenate((profUIDs0, profEXTs0), axis=1)
profAGRs1 = np.concatenate((profUIDs0, profAGRs0), axis=1)
profNEUs1 = np.concatenate((profUIDs0, profNEUs0), axis=1)
lsProfAGEs = profAGEs1.tolist()
print(lsProfAGEs[1])
ageDF = profiles[['userid', 'age']]
print(ageDF.columns.tolist())
ageDFo = profiles[['userid', 'age']]
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,myMax], right=False, labels=['xx-24','25-34','35-49','50+'])
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=['xx-24','25-34','35-49','50+'])
print(ageDFo.head())
profiles=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
ageDF = profiles[['userid', 'age']].copy()
ageDFo = profiles[['userid', 'age']].copy()
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=['xx-24','25-34','35-49','50+'])
profiles=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
ageDFo = profiles[['userid', 'age']].copy()
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=['xx-24','25-34','35-49','50+'])
ageGRPuids=ageDFo.ix[:,0]
ageGRPageGRPs=ageDFo.ix[:,2]
print(ageGRPuids.head())
print(ageGRPageGRPs.head())
profiles=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
ageDFo = profiles[['userid', 'age']].copy()
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=[1, 2, 3, 4])
ageGRPuids=ageDFo.ix[:,0].values
ageGRPageGRPs=ageDFo.ix[:,2].values
print(type(ageGRPuids)
)
profiles=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
ageDFo = profiles[['userid', 'age']].copy()
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=[1, 2, 3, 4])
ageGRPuids=ageDFo.ix[:,0].values
ageGRPgrps=ageDFo.ix[:,2].values
ageGRPuids0 = ageGRPgrps.reshape(9500,1)
ageGRPgrps0 = ageGRPgrps.reshape(9500,1)
profiles=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
ageDFo = profiles[['userid', 'age']].copy()
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=[1, 2, 3, 4])
ageGRPuids=ageDFo.ix[:,0].values
ageGRPgrps=ageDFo.ix[:,2].values
ageGRPuids0 = ageGRPgrps.reshape(9500,1)
print(type(ageGRPuids))
print(ageGRPuids.shape)
ageGRPSuids0 = ageGRPuids.reshape(9500,1)
ageGRPSgrps0 = ageGRPgrps.reshape(9500,1)
print(ageGRPgrps.shape)
ageGRPSgrps0 = ageGRPgrps.reshape(9500,1)
print(type(ageGRPgrps))
profiles=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
ageDFo = profiles[['userid', 'age']].copy()
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=['xx-24','25-34','35-49','50+'])
ageGRPuids=ageDFo.ix[:,0].values
ageGRPgrps=ageDFo.ix[:,2].values
print(type(ageGRPgrps))
profiles=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
ageDFo = profiles[['userid', 'age']].copy()
ageDFo['age_grp'] = pd.cut(ageDFo['age'], [0,25,35,50,150], right=False, labels=[1, 2, 3, 4])
ageGRPuids=ageDFo.ix[:,0].values
ageGRPgrps=ageDFo.ix[:,2].values
import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
likes = pd.read_csv("/Users/jamster/data/training/relation/relation.csv")
likesUIDs = likes.ix[:,1].values
likesLIDs = likes.ix[:,2].values
lsLikesUIDs = likesUIDs.tolist()
lsLikesLIDs = likesLIDs.tolist()
setLikesUIDs = set(lsLikesUIDs)
setLikesLIDs = set(lsLikesLIDs)
unqLikesUIDs = (list(setLikesUIDs))
unqLikesLIDs = (list(setLikesLIDs))
allLikesLS = [lsLikesUIDs, lsLikesLIDs]
allLikesLS = [lsLikesUIDs, [str(x) for x in lsLikesLIDs]]
allLikesLS = list(map(list, zip(*allLikesLS)))
aDictLikes2 = {}
for aUID in unqLikesUIDs:
	aDictLikes2[aUID]=[]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
combDICT = {}
for uid in unqLikesUIDs:
	tmpDICT={}
	tmpLS = aDictLikes2[uid]
	for row in tmpLS:
		tmpDICT[str(row)]=1
	combDICT[uid]=tmpDICT
tryTHIS=[]
for uid in unqLikesUIDs:
	tryTHIS.append(combDICT[uid])
from sklearn.feature_extraction import DictVectorizer
v = DictVectorizer()
comeON=v.fit_transform(tryTHIS)
profUIDs=profiles.ix[:,1].values
profAGEs=profiles.ix[:,2].values
profSEXs=profiles.ix[:,3].values
profOPEs=profiles.ix[:,4].values
profCONs=profiles.ix[:,5].values
profEXTs=profiles.ix[:,6].values
profAGRs=profiles.ix[:,7].values
profNEUs=profiles.ix[:,8].values
from sklearn import metrics
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.model_selection import KFold
profUIDs0 = profUIDs.reshape(9500,1)
profAGEs0 = profAGEs.reshape(9500,1)
profSEXs0 = profSEXs.reshape(9500,1)
profOPEs0 = profOPprofOPEape(9500,1)
profCONs0 = profCONs.reshape(9500,1)
profEXTs0 = profEXTs.reshape(9500,1)
profAGRs0 = profAGRs.reshape(9500,1)
profNEUs0 = profNEUs.reshape(9500,1)
profAGEs1 = np.concatenate((profUIDs0, profAGEs0), axis=1)
profSEXs1 = np.concatenate((profUIDs0, profSEXs0), axis=1)
profOPEs1 = np.concatenate((profUIDs0, profOPEs0), axis=1)
profCONs1 = np.concatenate((profUIDs0, profCONs0), axis=1)
profEXTs1 = np.concatenate((profUIDs0, profEXTs0), axis=1)
profAGRs1 = np.concatenate((profUIDs0, profAGRs0), axis=1)
profNEUs1 = np.concatenate((profUIDs0, profNEUs0), axis=1)
print(type(profAGEs1))
test = profiles.ix[:,1:8]
test = profiles.ix[:,1:8].values
testLS=test.tolist()
print(testLS[0])
profilesDF=pd.read_csv("/Users/jamster/data/training/profile/profile.csv")
profiles=profilesDF.ix[:,1:8].values
profilesLS=profiles.tolist()
profilesLSo=profiles.tolist()
for row in profilesLSo:
	tmpLS=row
	tmpAGE=row[1]
	if tmpAGE < 25:
		tmpLS[1]=1
	elif tmpAGE < 35:
		tmpLS[1]=2
	elif tmpAGE < 50:
		tmpLS[1]=3
	else:
		tmpLS[1]=4
profilesLS=[]
for row in profilesLSo:
     tmpLS=row
     tmpAGE=row[1]
     if tmpAGE < 25:
             tmpLS[1]=1
     elif tmpAGE < 35:
             tmpLS[1]=2
     elif tmpAGE < 50:
             tmpLS[1]=3
     else:
             tmpLS[1]=4
print(profilesLS[10])
profilesLS=[]
for row in profilesLSo:
     tmpLS=row
     tmpAGE=row[1]
     if tmpAGE < 25:
             tmpLS[1]=1
     elif tmpAGE < 35:
             tmpLS[1]=2
     elif tmpAGE < 50:
             tmpLS[1]=3
     else:
             tmpLS[1]=4
	profilesLS.append(tmpLS)
profilesLS=[]
for row in profilesLSo:
     tmpLS=row
     tmpAGE=row[1]
     if tmpAGE < 25:
             tmpLS[1]=1
     elif tmpAGE < 35:
             tmpLS[1]=2
     elif tmpAGE < 50:
             tmpLS[1]=3
     else:
             tmpLS[1]=4
	profilesLS.append(tmpLS)
numCMDs=readline.get_current_history_length()
for i in range((numCMDs-1)):
f = open("/Users/jamster/Desktop/commands11aC.txt", "w")
for i in range((numCMDs-1)):
	f.write(readline.get_history_item(i+1) + "\n")
f.close()
profilesLS=[]
for row in profilesLSo:
	tmpLS=row
	tmpAGE=row[1]
	if tmpAGE < 25:
		tmpLS[1]=1
	elif tmpAGE < 35:
		tmpLS[1]=2
	elif tmpAGE < 50:
		tmpLS[1]=3
	else:
		tmpLS[1]=4
	profilesLS.append(tmpLS)
print(profilesLS[10])
lsLikesUIDs[1]
profilesLS[1]
test=[]
test[1]=0
test=[]
for i in range(9500):
	test.append([])
profsTOlikes=[]
for i in range(9500):
	profsTOlikes.append([])
for row in profilesLS:
	tmpIND = lsLikesUIDs.index(row[0])
	profsTOlikes[tmpIND]=row
print(tmpIND)
print(len(lsLikesUIDs))
print(profilesLS[1])
print(unqLikesUIDs[1])
	test.append([])
profsTOlikes=[]
for row in profilesLS:
	tmpIND = unqLikesUIDs.index(row[0])
profsTOlikes=[]
for i in range(9500):
	profsTOlikes.append([])
for row in profilesLS:
	tmpIND = unqLikesUIDs.index(row[0])
	profsTOlikes[tmpIND]=row
print(profsTOlikes[1])
print(unqLikesUIDs[1])
profsTOlikesARR=np.array(profsTOlikes)
print(profsTOlikesARR)
profsTOlikesARR=profsTOlikesARR.transpose()
print(profsTOlikesARR)
print(profsTOlikesARR[1,40])
ages=profsTOlikes[1,:]
ages=profsTOlikes[1,0:9500]
print(np.arange(9500))
ages=profsTOlikes[1,np.arange(9500)]
ages=profsTOlikes[[1],np.arange(9500)]
ages=profsTOlikes[[1],np.arange(9500).toarray]
ages=profsTOlikes[[1],np.arange(9500).to_array()]
ages=profsTOlikes[[1],np.arange(9500)]
profsTOlikesARR=profsTOlikesARR.transpose()
print(profsTOlikesARR)
print(profsTOlikes[1])
profsTOlikes1=list(map(list, zip(*profsTOlikes)))
print(profsTOlikes1[1,1])
print(profsTOlikes1[1][1])
agesARR=np.array(profsTOlikes1[1])
print(agesARR.shape)
print(comeON.shape)
bernNB = BernoulliNB()
bernNB.fit(comeON, agesARR)
agesARRo=agesARR.copy()
agesARR=agesARR.reshape(9500,1)
bernNB.fit(comeON, agesARR)
agesARR=np.array(profsTOlikes1[1])
bernNB.fit(comeON, agesARR)
bernNB.score()
bernNB.score(comeON,agesARR)
