import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn import metrics
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn import svm
from sklearn.svm import SVC, LinearSVC
from sklearn.svm import SVR, LinearSVR
from sklearn import linear_model
from sklearn.externals import joblib
import timeit
import time
likes = pd.read_csv("/home/jamster/data/training/relation/relation.csv")
likesUIDs = likes.ix[:,1].values
likesLIDs = likes.ix[:,2].values
lsLikesUIDs = likesUIDs.tolist()
lsLikesLIDs = likesLIDs.tolist()
setLikesUIDs = set(lsLikesUIDs)
setLikesLIDs = set(lsLikesLIDs)
unqLikesUIDs = (list(setLikesUIDs))
unqLikesLIDs = (list(setLikesLIDs))
allLikesLS = [lsLikesUIDs, [str(x) for x in lsLikesLIDs]]
allLikesLS = list(map(list, zip(*allLikesLS)))
likes = None
aDictLikes2 = {}
for aUID in unqLikesUIDs:
	aDictLikes2[aUID]=[]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
combDICT = {}
for uid in unqLikesUIDs:
	tmpDICT={}
	tmpLS = aDictLikes2[uid]
	for row in tmpLS:
		tmpDICT[str(row)]=1
	combDICT[uid]=tmpDICT
tryTHIS=[]
for uid in unqLikesUIDs:
	tryTHIS.append(combDICT[uid])
v = DictVectorizer()
likesMAT=v.fit_transform(tryTHIS)
likesUIDs=None
likesLIDs=None
lsLikesUIDs=None
lsLikesLIDs=None
setLikesUIDs=Nonoe
setLikesUIDs=None
setLikesLIDs=None
unqLikesUIDs=None
unqLikesLIDs=None
allLikesLS=None
aDictLikes2=None
combDICT=None
tryTHIS=None
v=None
profilesDF=pd.read_csv("/home/jamster/data/training/profile/profile.csv")
profilesDF=None
from scipy.sparse.linalg import svds, eigs
combLIKES=likesMAT.transpose()*likesMAT
combLikes=combLIKES.tocsc()
likesMAT=None
from scipy.sparse.linalg import svds, eigs
u, s, vt = svds(combLIKES, k=1000)
print(u.shape)
np.savetxt('/home/jamster/u1000.csv', u, delimiter=",")
np.savetxt('/home/jamster/s1000.csv', s, delimiter=",")
np.savetxt('/home/jamster/vt1000.csv', vt, delimiter=",")
u = None
vt = None
s = None
combLIKES=None
quit()
from scipy.sparse import csc_matrix
from scipy.sparse.linalg import svds, eigs
A = csc_matrix([[1, 0, 0], [5, 0, 2], [0, -1, 0], [0, 0, 3]], dtype=float)
s = svds(A, k=2, return_singular_vectors=False)
print(s)
quit()
import readline
import scipy.sparse
import scipy
import numpy as np
import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn import metrics
from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn import svm
from sklearn.svm import SVC, LinearSVC
from sklearn.svm import SVR, LinearSVR
from sklearn import linear_model
from sklearn.externals import joblib
import timeit
import time
likes = pd.read_csv("/home/jamster/data/training/relation/relation.csv")
likesUIDs = likes.ix[:,1].values
likesLIDs = likes.ix[:,2].values
lsLikesUIDs = likesUIDs.tolist()
lsLikesLIDs = likesLIDs.tolist()
setLikesUIDs = set(lsLikesUIDs)
setLikesLIDs = set(lsLikesLIDs)
unqLikesUIDs = (list(setLikesUIDs))
unqLikesLIDs = (list(setLikesLIDs))
allLikesLS = [lsLikesUIDs, [str(x) for x in lsLikesLIDs]]
allLikesLS = list(map(list, zip(*allLikesLS)))
aDictLikes2 = {}
for aUID in unqLikesUIDs:
	aDictLikes2[aUID]=[]
for row in allLikesLS:
	aDictLikes2[row[0]].append(row[1])
combDICT = {}
for uid in unqLikesUIDs:
	tmpDICT={}
	tmpLS = aDictLikes2[uid]
	for row in tmpLS:
		tmpDICT[str(row)]=1
	combDICT[uid]=tmpDICT
tryTHIS=[]
for uid in unqLikesUIDs:
	tryTHIS.append(combDICT[uid])
v = DictVectorizer()
likesMAT=v.fit_transform(tryTHIS)
profilesDF=pd.read_csv("/home/jamster/data/training/profile/profile.csv")
profiles=profilesDF.ix[:,1:9].values.copy()
profilesLSo=profiles.tolist().copy()
profilesLS=[]
for row in profilesLSo:
	tmpLS=row
	tmpAGE=row[1]
	if tmpAGE < 25:
		tmpLS[1]=1
	elif tmpAGE < 35:
		tmpLS[1]=2
	elif tmpAGE < 50:
		tmpLS[1]=3
	else:
		tmpLS[1]=4
	profilesLS.append(tmpLS)
profsTOlikes=[]
for i in range(len(profilesLSo)):
	profsTOlikes.append([])
for row in profilesLS:
	tmpIND = unqLikesUIDs.index(row[0])
	profsTOlikes[tmpIND]=row
profsTOlikes1=list(map(list, zip(*profsTOlikes)))
agesARR=np.array(profsTOlikes1[1])
sexsARR=np.array(profsTOlikes1[2])
opesARR=np.array(profsTOlikes1[3])
consARR=np.array(profsTOlikes1[4])
extsARR=np.array(profsTOlikes1[5])
agrsARR=np.array(profsTOlikes1[6])
neusARR=np.array(profsTOlikes1[7])
attribs = [agesARR, sexsARR, opesARR, consARR, extsARR, agrsARR, neusARR]
labels = ['age', 'sex', 'ope', 'con', 'ext', 'agr', 'neu']
kf = KFold(n_splits=19)
aTMP = 0
for train_index, test_index in kf.split(agesARR):
	aTMP+=1
print(dir())
aDictLikes2=None
aTMP=None
aUID=None
agesARR=None
agrsARR=None
allLikesLS=None
attribs=None
vars = dir()
print(vars[10])
print(vars[15])
print(vars[17])
print(vars[19])
print(vars[21])
print(vars[24])
print(vars[22])
vars.remove(0:21)
vars.remove(rang(0:21))
vars.remove(rang(22))
vars.remove(range(22))
for i in range(21):
	vars.remove(0)
vars.pop()
vars = dir()
newVARS = []
for i in range(22,len(vars)):
	newVARS.append(vars[i])
print(newVARS)
vars=newVARS
newVARS=None
vars.remove(likesMAT)
vars.remove('likesMAT')
vars.remove('row')
vars.remove('vars')
for row in vars:
	eval(row + "=None")
	eval(row + =None)
for row in vars:
	eval(row + =None)
	eval(row =None)
for row in vars:
	eval(row =None)
for row in vars:
	del globals()[row]
dir()
newVARS=None
row=None
vars=None
import scipy
from scipy.sparse.linalg import eigs, svds
s = svds(likesMAT, k=6000, return_singular_vectors=False)
import numpy as np
np.savetxt('/home/jamster/s6000.csv', s, delimiter=",")
import readline
numCMDs=readline.get_current_history_length()
